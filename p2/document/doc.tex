\documentclass[12pt]{article}


\usepackage[pdftex,pdfpagelabels,bookmarks,hyperindex,hyperfigures]{hyperref}


\usepackage[margin=1in]{geometry}
\usepackage{float}
\usepackage{adjustbox}
\usepackage[table]{xcolor}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{pgfplots}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{listings}

\setlength{\parskip}{1em} % Add spacing between paragraphs
\setlength{\parindent}{0em} % Remove indentation at the start of paragraphs


\pagestyle{fancy}
\fancyhf{} % Clear all headers/footers
\lhead{Project Step 2}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}


% --- Title and TOC ---

\begin{document}

\title{4P78 Project Step 2}
\author{
    Parker TenBroeck 7376726\\
    pt21zs@brocku.ca
}
\date{\today}

\makeatletter
\begin{titlepage}
	\def \LOGOPATH {brock.jpg}
	\def \UNIVERSITY {Brock University}
	\def \FACULTY {Faculty of Mathematics \& Science}
	\def \DEPARTMENT {Department of Computer Science}
	\def \COURSETITLE {COSC 3P93: Parallel Computing}
	\def \SUPERVISOR {Robson De Grande}
	
	
	\vfill
	\begin{center}
		\includegraphics[width=0.6\textwidth]{brock.jpg}
		\fontsize{14pt}{14pt}\selectfont
		\vfill
		\UNIVERSITY \\
		\FACULTY \\
		\DEPARTMENT \\
		\vfill
		\fontsize{18pt}{18pt}\selectfont
		\textbf{\COURSETITLE} \\[0.5cm]
		\textbf{\@title}
		\vfill
		\fontsize{14pt}{14pt}\selectfont
		Prepared By: \\[0.5cm]
		
		\begin{tabular}[t]{c}
			\@author
		\end{tabular}\par
	
	    \vfill
		Instructor: \\
		\SUPERVISOR
		\vfill
		\@date
	\end{center}
\end{titlepage}
\makeatother

\newpage

\section{Intro}
My topic is rendering of triangle meshes. \\

This topic is explored in great depth and has a wide array of different techniques and optimizations to produce varying levels of realism. Additionally parallelization often goes hand in hand when talking about these techniques as they are designed for GPUs. \\

I wanted to implement a set of rendering techniques which offer a good balance between being practical to implement, possible to parallelize, low cost enough to potentially run in real time (30-60 FPS), and be visually interesting. I decided to implement Blinn-Phong shading with the option for ambient/diffuse/specular maps. as well as normal maps. As you will see in some of the demo animations the results are quite visually appealing. 

I heavily relied on material and techniques talked about on the Learn OpenGL\cite{learn-open-gl} website.

\section{Algorithm Overview}

There are a 4 major steps involved in this process

\begin{enumerate}
	\item Transforming from local space to clip space through the Projection, View, and Model matrices
	\item Clipping out of view verticies and triangles.
	\item Rasterizing triangles to the frame buffer
	\item Performing per fragment(pixel) lighting 
\end{enumerate}


\subsection{Projection}
the projection matrix translates coordinates into clip space \eqref{clip-bounds}.
\begin{gather*}\begin{align}
	&fov = \text{the field of view for our camera} \notag\\
	&far = \text{the farthest point our camera can see} \notag\\
	&near = \text{the closest point our camera can see} \notag\\
	&M_{projection} = 
	\begin{bmatrix} 
		\frac{1}{aspect*\tan(\frac{fov}2)}&0&0&0\\
		0&\frac{1}{\tan(\frac{fov}2)}&0&0\\
		0&0&-\frac{far+near}{far-near}&-\frac{2\times far \times near}{far-near}\\
		0&0&-1&0
	\end{bmatrix}
\end{align}\end{gather*}


\subsection{View}
The view matrix transforms world space coordinates into view space coordinates where x is left and right, y is up and down, and z is depth.
\begin{gather*}\begin{align}
	&P_{target} = \text{Where the camera is looking} \notag\\
	&P_{eye} = \text{Where the camera is} \notag\\
	&\overrightarrow{V_{world\hspace{0.2em}up}} = \text{the up direction of the world }\left\langle \begin{matrix}0&1&0\end{matrix} \right\rangle \notag\\
	&\overrightarrow{V_{cam\hspace{0.2em}forward}} = \left\langle P_{target}-P_{eye} \right\rangle \notag\\
	&\overrightarrow{V_{cam\hspace{0.2em}right}} = \left\langle \overrightarrow{V_{cam\hspace{0.2em}forward}}\times  \overrightarrow{V_{world\hspace{0.2em}up}}\right\rangle \notag\\
	&\overrightarrow{V_{cam\hspace{0.2em}up}} = \left\langle \overrightarrow{V_{cam\hspace{0.2em}right}}\times  \overrightarrow{V_{cam\hspace{0.2em}forward}}\right\rangle \notag\\
	&M_{view}= 
	\begin{bmatrix}
		\overrightarrow{V_{cam\hspace{0.2em}right}}_x&\overrightarrow{V_{cam\hspace{0.2em}right}}_y&\overrightarrow{V_{cam\hspace{0.2em}right}}_z&\overrightarrow{V_{cam\hspace{0.2em}right}}\cdot P_{eye}\\
		\overrightarrow{V_{cam\hspace{0.2em}up}}_x&\overrightarrow{V_{cam\hspace{0.2em}up}}_y&\overrightarrow{V_{cam\hspace{0.2em}up}}_z&\overrightarrow{V_{cam\hspace{0.2em}up}}\cdot P_{eye}\\
		-\overrightarrow{V_{cam\hspace{0.2em}forward}}_x&-\overrightarrow{V_{cam\hspace{0.2em}forward}}_y&-\overrightarrow{V_{cam\hspace{0.2em}forward}}_z&\overrightarrow{V_{cam\hspace{0.2em}forward}}\cdot P_{eye}\\
		0&0&0&1
	\end{bmatrix}
\end{align}\end{gather*}

\subsection{Model}

The model matrix transforms coordinates from their local model positions to world space. 
\begin{gather}\begin{align}
		&P_{pos} = \text{world space location of the object} \notag\\
		&\overrightarrow{V_{scale}} = \text{x, y, z scale of object} \notag\\
		&A_{rotation} = \text{euler angles of objects rotation, raw,pitch,roll} \notag\\
		%
		&M_{yaw} = \begin{bmatrix}
			\cos(yaw)&-\sin(yaw)&0\\
			\sin(yaw)&\cos(yaw)&0\\
			0&0&1
		\end{bmatrix} \notag\\
		&M_{pitch} = \begin{bmatrix}
			\cos{pitch}&0&\sin(pitch)\\
			0&1&0\\
			-\sin{pitch}&0&\cos{pitch}
		\end{bmatrix} \notag\\
		&M_{roll} = \begin{bmatrix}
			1&0&0\\
			0&\cos(roll)&-\sin(roll)\\
			0&\sin(roll)&\cos(roll)
		\end{bmatrix} \notag\\
		%
		&M_{rot} = M_{yaw} \cdot M_{pitch} \cdot M_{roll} \notag \\
		%
		&M_{scale} = \begin{bmatrix}
			\overrightarrow{V_{scale}}_x&0&0\\
			0&\overrightarrow{V_{scale}}_y&0\\
			0&0&\overrightarrow{V_{scale}}_z
		\end{bmatrix} \notag\\
		&M_{rot\hspace{0.2em}scale} = M_{rot}\cdot M_{scale} \notag\\
		&M_{model} = \begin{bmatrix}
			{M_{rot\hspace{0.2em}scale}}_{11}&{M_{rot\hspace{0.2em}scale}}_{12}&{M_{rot\hspace{0.2em}scale}}_{13}&{P_{pos}}_x\\
			{M_{rot\hspace{0.2em}scale}}_{21}&{M_{rot\hspace{0.2em}scale}}_{22}&{M_{rot\hspace{0.2em}scale}}_{23}&{P_{pos}}_y\\
			{M_{rot\hspace{0.2em}scale}}_{31}&{M_{rot\hspace{0.2em}scale}}_{32}&{M_{rot\hspace{0.2em}scale}}_{33}&{P_{pos}}_z\\
			0&0&0&1
		\end{bmatrix}
\end{align}\end{gather}

\subsection{Clip}


\begin{gather*}\begin{aligned}
	V_{world} &= M_{model} \cdot V_{local} \notag\\
	V_{clip} &= M_{projection} \cdot M_{view} \cdot M_{model} \cdot V_{local} \notag\\
	%
	M_{normal} &= {{M_{model}}^{-1}}^T \notag\\
	\left\langle N_{world} \right\rangle &= M_{normal} \cdot \left\langle N_{local} \right\rangle \notag
\end{aligned}\end{gather*}

If the resulting vertex is outside this range it is not visible and can be clipped.
\begin{gather}
		-{V_{clip}}_w \leq {V_{clip}}_x \leq {V_{clip}}_w \label{clip-bounds}\\
		-{V_{clip}}_w \leq {V_{clip}}_y \leq {V_{clip}}_w \notag\\
		-{V_{clip}}_w \leq {V_{clip}}_z \leq {V_{clip}}_w \notag
\end{gather}

\subsection{Depth Perspective}
After clipping each vertexs $x,y,z$ components are divided by their $w$ component to give depth perspective. 

\subsection{Screen Space}
After depth perspective the $x,y$ components are shifted over by $\frac12$ then scaled to the screen width and height.


\subsection{Rasterization}
The rasterizer first finds a bounding box around the screen space coordinates. Then iterates over each pixel in the box finding the barycentric coordinates at that pixel. It uses these to determine if the point is actually in the triangle or not. and if it is find the liniarly interpreted world position, uv, normal, tangent, and bitangent at that point from the three points defining the triangle.

\subsubsection{Perspective Correction}
World position, uv, normal, tangent, and bitangent all need to be perspective corrected when being linearly interpolated during rasterization. This is done by scaling each vector type by $\frac1w$, doing the linear interpolation between face points. then scaling the resulting interpolated vector again by a linearly interpolated $\frac1w$.

\subsection{Fragment}
The fragment uses Binn-Phong shading 
\begin{gather*}\begin{aligned}
		\left\langle \overrightarrow{V_{light\hspace{0.2em}dir}} \right\rangle
			&=
			\left\langle P_{light}-P_{fragment}\right\rangle \notag\\
		%
		\text{light power} 
			&= 
			\frac{\text{light intensity}}{| P_{light}-P_{fragment}|^2}\\
		%
		\text{lambertian} 
			&= \max(0, \left\langle 
			\overrightarrow{V_{light\hspace{0.2em}dir}} \right\rangle \cdot   \left\langle N_{fragment}\right\rangle) \\
		%
		\left\langle\overrightarrow{V_{view\hspace{0.2em}dir}} \right\rangle 
		&= 
		\left\langle P_{eye}-P_{fragment}\right\rangle\\
		%
		\left\langle\overrightarrow{V_{half\hspace{0.2em}dir}} \right\rangle 
		&= 
			\left\langle 
				\left\langle\overrightarrow{V_{view\hspace{0.2em}dir}} \right\rangle
				+
				\left\langle \overrightarrow{V_{light\hspace{0.2em}dir}}  \right\rangle
			\right\rangle \\
		%
		\text{specular} &= \max(0, 
			\left\langle\overrightarrow{V_{half\hspace{0.2em}dir}} \right\rangle
			\cdot
			\left\langle N_{fragment}\right\rangle			
		)^{\text{fragment shininess}}\\
		%
		C_{\text{spec}} &= C_{light}\times \text{specular} \times \text{light power}\\
		%
		C_{\text{diff}} &= C_{light}\times \text{lambertian} \times \text{light power}
\end{aligned}\end{gather*}


\section{Performance}
The following tables are the performance tests for 2 different scenes each at 720p and 1080p. The rendered animations can be found here
\href{https://github.com/ParkerTenBroeck/3P93/blob/b09e7ca83aa0af8b57b7c728cc38519cd7d9188d/p2/code/examples/bricks.webp}{bricks.webp}
and here
\href{https://github.com/ParkerTenBroeck/3P93/blob/dff1995021a7f66e8c5a2a137551acbd2b20739f/p2/code/examples/halo.webp}{halo.webp}. (please look at the halo one its really cool)


\begin{table}[H]
	\caption{Performance Bench Bricks 1080p}
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Resolution& 1920x1080\\\hline
		Time& 229.49 ms/frame\\\hline
		CPU&12th Gen Intel i3-12100F (8) @ 4.300GHz\\\hline
		OS&NixOS 25.05 (Warbler) x86\_64\\\hline
		RAM&32GiB\\\hline
		Compiler&clang version 19.1.7\\\hline
		Triangles&752456\\\hline
		Frames&300\\\hline
	\end{tabular}
	\label{table:performance-1080-brick}
\end{table}

\begin{table}[H]
	\caption{Performance Bench Bricks 720p}
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Resolution& 720x480\\\hline
		Time& 77.38 ms/frame\\\hline
		CPU&12th Gen Intel i3-12100F (8) @ 4.300GHz\\\hline
		OS&NixOS 25.05 (Warbler) x86\_64\\\hline
		RAM&32GiB\\\hline
		Compiler&clang version 19.1.7\\\hline
		Triangles&752456\\\hline
		Frames&300\\\hline
	\end{tabular}
	\label{table:performance-720-brick}
\end{table}

\begin{table}[H]
	\caption{Performance Bench Halo 1080p}
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Resolution& 1080x1920\\\hline
		Time& 54.77 ms/frame\\\hline
		CPU&12th Gen Intel i3-12100F (8) @ 4.300GHz\\\hline
		OS&NixOS 25.05 (Warbler) x86\_64\\\hline
		RAM&32GiB\\\hline
		Compiler&clang version 19.1.7\\\hline
		Triangles&42600\\\hline
		Frames&300\\\hline
	\end{tabular}
	\label{table:performance-1080-halo}
\end{table}

\begin{table}[H]
	\caption{Performance Bench Halo 720p}
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Resolution& 480x720\\\hline
		Time& 14.42 ms/frame\\\hline
		CPU&12th Gen Intel i3-12100F (8) @ 4.300GHz\\\hline
		OS&NixOS 25.05 (Warbler) x86\_64\\\hline
		RAM&32GiB\\\hline
		Compiler&clang version 19.1.7\\\hline
		Triangles&42600\\\hline
		Frames&300\\\hline
	\end{tabular}
	\label{table:performance-720-halo}
\end{table}

As you can see from the performance data the cost per frame relies much more on the number of pixels present and much less on the number of triangles being drawn. This gives us a clear target for parallelization being the rasterization stage and fragment shader stage.


\section{Paralization Opportunity}
The code has been setup in a way such that paralization 

\begin{enumerate}
	\item Mesh data is immutable and stored behind a shared pointer allowing access from multiple threads
	\item Texture data is immutable and stored behind a shared pointer as well.
	\item Scene data is light weight and can be copied with little cost if needed.
	\subitem Scene data is the \texttt{Camera}, \texttt{Light}s, and \texttt{Object}s.
	\subitem \texttt{Object}s only contain a shared pointer to their meshes and material textures so copying them is not costly.
	\item When rendering everything aside from the frame buffer and local calculations are immutable and do not depend on eachother for computation.
\end{enumerate}

\subsection{Per Frame}
The easiest approach is to render each frame in parallel. Because Mesh and Texture data is immutable it can be shared across any number of renderers running in parallel. The only cost would be creating the scene data for each frame running in parallel.

The major downside is each individual frame would still take the same amount of time. This is an issue if we want to use the renderer for real time applications like games.

Additionally each renderer would need its own frame buffer which can be quite large since each fragment(pixel) needs a significant amount of information like ambient, diffuse, specular color and texture data, world position, normal, tangent, bitangent. and more. A 1080x1920 frame buffer is $\sim 250MB$.

\subsection{Per Triangle}
\subsubsection{Per Vertex}
The calculations per vertex are all independent of eachother making them a good target for parallelization.

\subsubsection{Rasterization}
Rasterization is the one part of this process which would significantly benifit from parallelization but has considerations that make that difficult. If rasterization were to be parallelized and because each triangle can draw to any position on the screen there could be cases where two threads draw to the same pixel at the same time. This can cause issues since each pixel only is drawin if its depth is less than the depth currently drawn to that pixel. Keeping this guarentee and preventing data races special care would need to be taken to ensure the check and write of each pixel is atomic.

\subsection{Per Fragment (Pixel)}
Each pixel is completely independent from eachother at this stage. The only information each fragment might need is $P_{eye}$ and scene lighting information. Luckily all that data is immutable at this stage so can safely be parallelized with no considerations.

\subsection{Combination}
Each of these parallelization opportunities happen at different stages so any number of them can be combined together.

\section{Libraries Used}

Used \texttt{tinyobjloader}\cite{tinyobjloader} for loading and parsing OBJ and MTL files.\\
\\
Used \texttt{stb\_image}\cite{stb-image} for loading and parsing texture files into linear RGB.\\
\\
Used \texttt{stb\_image\_write}\cite{stb-image-write} for writing rendered frames to disk.

These libraries are only used in the setup of the program when loading the 3D objects and material textures. They have no impact on the rendering performance.

\section{Building and Runing}

It is \underline{Highly} reccomended to use Clang when building this project. Clang has much better instruction vectorization optimizations than GCC typically runs 5 times faster (this is only a rough estimate). 
\\

Two seperate build files are provided for each respective compiler \texttt{build\_clang.sh} and \texttt{build\_gcc.sh}. \\
\\
\underline{Important}: to switch between building with gcc or clang you \texttt{must} completely delete the build folder if it has been created previously with the other build script.\\

Once the project has been built you can run it with the \texttt{run.sh} script. Which will run the same scene used in \ref{table:performance-1080-brick}. 300 frames will be written to \texttt{/animation} which can be combined into a animated video with either \texttt{make\_mp4.sh} or \texttt{make\_webp.sh} (optional). \\

You can specify the resolution of the animation by changing the parameters to the program in \texttt{run.sh}.


\nocite{*}
\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
